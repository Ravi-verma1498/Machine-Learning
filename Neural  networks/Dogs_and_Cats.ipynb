{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo7GDwjyzBwf",
        "outputId": "88e79e89-d331-47c2-e7e2-f561b0e4a8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after 'kaggle.json!/.kaggle/'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json!/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk9JTPxDzk5T",
        "outputId": "cf3118e3-38c3-4b2e-90b8-275fc5478c85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n",
            "License(s): unknown\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 1.04G/1.06G [00:09<00:00, 225MB/s]\n",
            "100% 1.06G/1.06G [00:09<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtP5y7ktzk-J"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "z = zipfile.ZipFile('/content/dogs-vs-cats.zip','r')\n",
        "z.extractall('/content')\n",
        "z.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZa1YF_2zlEa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZTZCaE1c_i"
      },
      "source": [
        "Using Generator hlep to divide data in batches to process large amount of data as this kind of data we are working on is very large we need generator for both training and validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdIMTINezlG9",
        "outputId": "1efc3216-b1c3-49a7-8d55-53cc7fac6800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# generator image datasets from directory\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/train',\n",
        "    labels = 'inferred', # it label cat and dog 1 and 0 respectively or viceversa\n",
        "    batch_size = 32,\n",
        "    image_size = (256,256) # we need this as size of each image in data are not same\n",
        "\n",
        "\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1giudbCAzlKo",
        "outputId": "0330582f-4302-44ac-dcbe-4a43d6a0d6fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/test',\n",
        "    labels = 'inferred',\n",
        "    batch_size = 32,\n",
        "    image_size = (256,256) # we need this as size of each image in data are not same\n",
        "\n",
        "\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rs8PX3jI3I6W"
      },
      "outputs": [],
      "source": [
        "# Normalise all pixels  1-255 into 0-1\n",
        "def process(image,label):\n",
        "  image=tf.cast(image/255.,tf.float32)\n",
        "  return image,label\n",
        "train_ds = train_ds.map(process)\n",
        "test_ds = test_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDm4eBQk3I94"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size = (3,3),padding ='valid',activation = 'relu',input_shape = (256,256,3)))\n",
        "model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size = (3,3),padding ='valid',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size = (3,3),padding ='valid',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = 'valid'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation = 'relu'))\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvQec-Fa6E5h",
        "outputId": "5f5f111b-aacd-4621-915a-e684ca9a83fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               14745728  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14847297 (56.64 MB)\n",
            "Trainable params: 14847297 (56.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWbhOyfY6E87"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bedqmVmc3JHY",
        "outputId": "7eff5c58-4689-4b85-fce7-09f41edc08b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 3167s 5s/step - loss: 0.6100 - accuracy: 0.6528 - val_loss: 0.4940 - val_accuracy: 0.7598\n",
            "Epoch 2/10\n",
            " 85/625 [===>..........................] - ETA: 41:31 - loss: 0.5080 - accuracy: 0.7507"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds,epochs = 10,validation_data = test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP2rLpRp3JKz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}